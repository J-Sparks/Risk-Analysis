---
title: "APR Risk Analysis-using Applicants Data"
author: "Jay Kim"
date: "12/8/2021"
output: html_document
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE, warning=FALSE)
#source("DataShaping_Risk_AnalysisV0.R")
```

### Import Data

```{r message=FALSE, warning=FALSE}
## From ACCEPTANCE Folder
library(readr)
applicants_2017to2021_COM_HSGPA2021V0 <- read_csv("G:/Shared drives/HMCSE-PAM Lab/Jay's Space/2021 Active Projects/08/ACCEPTANCE RATE/all_applicants20172021/applicants_2017to2021_COM_HSGPA2021V0.csv") %>% 
    mutate(OFFER_GPA = ifelse(is.na(OFFER_GPA), GPA_HIGHSCHOOL, OFFER_GPA))  %>% 
    mutate(OFFER_GPA= ifelse(OFFER_GPA < 2.0, NA, OFFER_GPA )) %>% # error HAGPA
    mutate(HS_NAME = ifelse(HS_NAME =="Titusville Astronaut HS", "Astronaut High School",HS_NAME)) %>% 
    mutate(HS_CEEB = ifelse(is.na(HS_CEEB), "N/A", HS_CEEB), HS_NAME = ifelse(is.na(HS_NAME), "N/A", HS_NAME)) %>% 
    filter(!is.na(Cohort))
### FTIC 2021
FTIC2021_APR <-  applicants_2017to2021_COM_HSGPA2021V0 %>% 
    filter(Cohort == 2021) # tier scores are fixed

 
# trim data
import_data <- applicants_2017to2021_COM_HSGPA2021V0 %>% 
    filter(!is.na(APR))  # exclude withdrawn FTIC
addmargins(table(import_data$APR))  # overall APR=0.8047324  
risk_apr_data <- import_data    
#colSums(is.na(risk_apr_data))

```

### High School APR (2017-2020)

```{r HS DataShaping}
HS_apr <- risk_apr_data %>% select(HS_CEEB, HS_NAME,HS_CNTY, APR, Cohort) %>% 
    filter(!is.na(.)) %>% 
    group_by(HS_CEEB,HS_NAME, APR) %>% 
     summarise(Count=n(), .groups = "drop") %>% 
    tidyr::pivot_wider(names_from = APR, values_from = Count) %>% 
    replace(is.na(.), 0) %>% 
    mutate(HS_Total = (Yes+No), HS_APR_Rate= round(Yes/HS_Total,4)) %>% 
    mutate(HS_APR_Rate = ifelse(HS_APR_Rate < 0.25, 0.20, HS_APR_Rate)) %>% # replace 0% apr to 20%
    arrange(HS_APR_Rate)

HS_apr[which(duplicated(HS_apr$HS_CEEB)),]
HS_apr[HS_apr$HS_CEEB=="101758",]
HS_apr[which(duplicated(HS_apr$HS_NAME)),] # fixed #line 19
risk_apr_data[risk_apr_data$HS_NAME=="Southside High School",] # came from different CNTY
HS_apr[HS_apr$HS_NAME=="N/A",] # not applicable 0.7

# density plot
hist(HS_apr$HS_APR_Rate, breaks = 25, col= "pink") 
# add normal curve
plot(density(HS_apr$HS_APR_Rate), col="blue")
 
write.csv(HS_apr[,c(1,5,6)], "HS_APR20172020_V0.csv", row.names = F)
```

### Program APR  


```{r}

PROG_apr <- risk_apr_data %>% select(PROGRAM_CODE, PROGRAM_DESC, APR, Cohort) %>% 
    filter(!is.na(.)) %>% 
    group_by(PROGRAM_DESC,PROGRAM_CODE, APR) %>% 
     summarise(Count=n(), .groups = "drop") %>% 
    tidyr::pivot_wider(names_from = APR, values_from = Count) %>% 
    replace(is.na(.), 0) %>% 
    mutate(PROG_Total = (Yes+No), PROG_APR_Rate= round(Yes/PROG_Total,4)) %>% 
    mutate(PROG_APR_Rate = ifelse(PROG_APR_Rate < 0.25, 0.20, PROG_APR_Rate)) %>% 
    arrange(PROGRAM_DESC)

PROG_apr

#density plot
hist(PROG_apr$PROG_APR_Rate, breaks = 25, col= "yellow") 
plot(density(PROG_apr$PROG_APR_Rate), col="green")
  

write.csv(PROG_apr[,c(1,2,5,6)], "PROGRAM_APR20172020V0.csv", row.names = F) #Nursing/ BSN Program is not in 2021
```

### Merge APR Rate in the Imported Data

```{r}
library(readr)
HS_APR20172020_V0 <- read_csv("G:/Shared drives/HMCSE-PAM Lab/Jay's Space/_HIGH_PRIORITY_PROJECTS/APR/APR FTIC2021/HS_APR20172020_V0.csv")
PROGRAM_APR20172020V0 <- read_csv("G:/Shared drives/HMCSE-PAM Lab/Jay's Space/_HIGH_PRIORITY_PROJECTS/APR/APR FTIC2021/PROGRAM_APR20172020V0.csv")

# hs apr
trim_apr_data1 <- merge( applicants_2017to2021_COM_HSGPA2021V0,HS_APR20172020_V0, by="HS_CEEB",all.x = T)
colSums(is.na(trim_apr_data1))
NA_HSNAME2021 <- trim_apr_data1[is.na(trim_apr_data1$HS_APR_Rate),] #211
trim_apr_data1[is.na(trim_apr_data1$HS_APR_Rate), "HS_APR_Rate"] <- 0.80 # replace overall apr rate 
colSums(is.na(trim_apr_data1))
# program apr
trim_apr_data2 <- merge( trim_apr_data1,PROGRAM_APR20172020V0, by="PROGRAM_CODE",all.x = T)
trim_apr_data2_ <- trim_apr_data2[!duplicated(trim_apr_data2$UWFID),] #5295
NA_PROG2021 <- trim_apr_data2_[is.na(trim_apr_data2_$PROG_APR_Rate),] #18
trim_apr_data2_[is.na(trim_apr_data2_$PROG_APR_Rate), "PROG_APR_Rate"] <- 0.80 # replace overall apr rate 
colSums(is.na(trim_apr_data2_))
addmargins(table(trim_apr_data2_$APR))

### used regression methods for imputatiom
#trim_apr_data1_imp <- merge( applicants_2017to2021_COM_HSGPA2021V0,HS_APR20172020_V0, by="HS_CEEB",all.x = T)




write.csv(trim_apr_data2_, "trim_apr_data2_V0.csv", row.names = F)




```


# Risk Analysis

```{r}

library(caret)
library(tidyverse)  # data manipulation and visualization
library(modelr)     # provides easy pipeline modeling functions
library(broom)      # helps to tidy up model outpu
library(readr)
trim_apr_data2_V0 <- read_csv("trim_apr_data2_V0.csv") 
colSums(is.na(trim_apr_data2_V0))
vari_apr1 <- c("PROG_APR_Rate","HS_APR_Rate","GENDER","OFFER_GPA","HS_FOREIGN_LANG","MY_UWF_STATUS")
```

```{r description}
apr_data1 <- trim_apr_data2_V0 %>% 
    mutate(APR= factor(APR)) %>% 
    select(APR, vari_apr1) %>% filter(!is.na(OFFER_GPA)) %>% filter(!is.na(APR)) 
colSums(is.na(apr_data1))
vari_apr2 = c ("HSGPA_tenths")

library(gtsummary)
summary_by_APR <- apr_data1 %>%  mutate(APR = ifelse(APR =="Yes", 1,0))  %>% 
    tbl_summary( by = APR,
                statistic = all_continuous() ~ "{mean} ({sd}) {min} {max}",
                missing = "no"
                            ) %>% add_n() 

summary_by_APR

```
### Correlation

```{r}
library(corrgram)
library(corrplot)
num.vari.cor <- trim_apr_data2_V0[c(2,3,5)] %>% na.omit()
cor.vari <- cor(num.vari.cor)
cor.vari

corrplot(cor.vari, method = "pie" )
#corrgram(cor.vari)
```

```{r modeling}
#data partition
TrainingIndex <- createDataPartition(apr_data1$APR, p=0.7, list = FALSE)
TrainingSet <- apr_data1[TrainingIndex,] # Training Set
TestingSet <- apr_data1[-TrainingIndex,] # Test Set

# Build model using all factors and labels
set.seed(111)
admitted_glm <- glm(APR ~ ., data = TrainingSet, family="binomial")
summary(admitted_glm)
exp(coef(admitted_glm))
P_value <- broom::tidy(admitted_glm)

#coefficient
coef1 <- exp(coef(admitted_glm))
coef_table <- knitr::kable(coef1)
coef_table
vari_imp <- knitr::kable(caret::varImp(admitted_glm))
vari_imp

#accuracy train data 
p_1 <- predict(admitted_glm, TrainingSet, type="response")
pred_1 <- ifelse(p_1>0.5, 1,0)
tab_1 <- table(Predicted=pred_1, Actural=TrainingSet$APR)
tab_1
round(sum(diag(tab_1))/sum(tab_1),4)  
#test data
p_2 <- predict(admitted_glm, TestingSet, type="response")
#ROC Curve ( not always right to choose)
model_AUC <- colAUC(p_2, TestingSet$APR, plotROC = T)
abline(h = model_AUC, col="blue")
text(0.2, 0.9, cex= 0.8, labels = paste("Optimal Value for cutoff:", round(model_AUC,4)))

pred_2 <- ifelse(p_2 > 0.5, 1,0) # in this analysis 0.5 works better
tab_2 <- table(Predicted=pred_2, Actural=TestingSet$APR)
tab_2
round(sum(diag(tab_2))/sum(tab_2),4)  
### goodness of fit
with(admitted_glm, pchisq(null.deviance - deviance, df.null-df.residual, lower.tail=F)) 
#anova(admitted_glm, admitted_glm_re, test = "Chisq")

#save model
saveRDS(admitted_glm, "./RISK_APR_MODEL_glmV0.rds")





```

### Using ueuralnet
### Modeling #2

```{r modeling 2}
library(MASS)

apr.dummy <- URM.dummy   
# num.vari <- apr.dummy[1:4]
# apr.vari <- apr.dummy[c(5:7,12)] #12 apr
all.num.vari <- apr.dummy[2:12]
##normalized data
maxs <- apply(all.num.vari, 2, max);maxs
mins <- apply(all.num.vari, 2, min);mins

#scaled
scaled.data.all <- scale(all.num.vari, center =  mins, scale = maxs - mins) %>%  as.data.frame()
hist(scaled.data.all$OFFER_GPA) # range from 0 to 1
 
scaled.data <- cbind(scaled.data.all, APR=apr.dummy$APR)
str(scaled.data)
colnames(scaled.data) <- c("Program_RATE", "HighSchool_RATE","Gender","HSGPA","HSForeignLang","UWFStatus","PellELGBL","CollegeExperienced","TraditionFTIC","Age","NewHSEntered","APR")
#partition
library(caTools)
set.seed(333)
split <- sample.split(scaled.data$APR, SplitRatio = 0.7 )
train_nn <- subset(scaled.data, split == TRUE)   # Training Set
test_nn <- subset(scaled.data, split == FALSE)  # Test Set
glimpse(train_nn)
# factors_f
n_factor <- names(train_nn)
f <- as.formula(paste("APR ~", paste(n_factor[!n_factor %in% "APR"], collapse = " + ")))
# package
#install.packages("neuralnet")
library(neuralnet)
set.seed(333)
apr_nn <- neuralnet(f, data = train_nn, hidden = c(2,2),   linear.output = FALSE , likelihood = TRUE, threshold = 0.05 ) 
print(apr_nn$weights)
plot(apr_nn, 
     col.hidden = "darkblue",
     col.hidden.synapse = "darkgreen",
     show.weights = T,
     information = T,
     fill = "yellow") 

# prediction
# apr_nn$result.matrix
# apr_nn$net.result
#predicted train
predicted.train <- neuralnet::compute(apr_nn, train_nn[1:11])
head( predicted.train$net.result,10)
pred_1 <- ifelse(predicted.train$net.result > 0.5, 1,0)
head(pred_1,10)
#confusion matrix
table(pred_1[,2], train_nn$APR) #2455/2866 0.8566


#predicted test
predicted.test <- neuralnet::compute(apr_nn, test_nn[1:11])
head(predicted.test$net.result,10)

predictions.test <- ifelse(predicted.test$net.result > 0.5, 1,0)
head(predictions.test,10)
#confusion matrix
table(predictions.test[,2], test_nn$APR) #1040/1229 0.8469
```


### Export Results

```{r}
NEWFTIC <- trim_apr_data2_V0 %>% filter(Cohort == 2021) 

new_FTIC_data <- NEWFTIC %>% 
    mutate(APR= factor(APR)) %>% 
    select(APR, vari_apr1) #%>% filter(!is.na(OFFER_GPA))

#call model
RISK_APR_MODEL <- readRDS("RISK_APR_MODEL_glmV0.rds")
#prediction
PREDICTION_NEWFTIC <- round(predict(RISK_APR_MODEL, new_FTIC_data, type="response"),4)
hist(PREDICTION_NEWFTIC)

PREDICTION_DF <- cbind(NEWFTIC, PREDICTION_NEWFTIC)
PREDICTION_DF$codeProb_APR <- ifelse(PREDICTION_DF$PREDICTION_NEWFTIC >= 0.90,"low-risk",
                                    ifelse(PREDICTION_DF$PREDICTION_NEWFTIC >= 0.60,"moderate-risk","high-risk"))
colSums(is.na(PREDICTION_DF)) 
unique(PREDICTION_DF$CURRICULUM_COLL)
library(stringr)
PREDICTION_DF1 <- PREDICTION_DF %>% arrange(CURRICULUM_COLL) %>% 
    mutate(College2021 = ifelse( CURRICULUM_COLL == "B", "COB",
                            ifelse(CURRICULUM_COLL == "P" , "CEPS",
                                ifelse(CURRICULUM_COLL ==  "H" , "CASSH",
                                    ifelse(CURRICULUM_COLL ==  "M" , "UKCOH",
                                        ifelse(CURRICULUM_COLL == "A" , "HMCSE",
                                            ifelse(CURRICULUM_COLL == "0" , "UNA", NA)))))))  %>% 
    mutate(Department2021 = CURRICULUM_DEPT, Program2021 = PROGRAM_DESC.y ,
           TIER2021 = TIER_SCORE.y)

unique(PREDICTION_DF1$College2021)

xtabs(~PREDICTION_DF1$College2021 + PREDICTION_DF1$codeProb_APR)
# export resutls
write.csv(PREDICTION_DF1,"OUTPUT_PREDICTION_NEWFTIC2021V0.csv", row.names = F) # removed 11 since missing HSGPA
colSums(is.na(PREDICTION_DF1))




```


```{r}
library(tidyverse)
g_apr_prop <- PREDICTION_DF %>%
    ggplot() +
    geom_bar(aes(x=codeProb_APR, fill=CURRICULUM_COLL))
plotly::ggplotly(g_apr_prop)
```

### FTIC2021 add first Term UWF GPA information

```{r  FTIC 2021 Fall1 GPA}


library(readr)
OUTPUT_PREDICTION_NEWFTIC2021V0 <- read_csv("G:/Shared drives/HMCSE-PAM Lab/Jay's Space/_HIGH_PRIORITY_PROJECTS/APR/APR FTIC2021/OUTPUT_PREDICTION_NEWFTIC2021V0.csv")
FTIC2021_ID_GPA <- OUTPUT_PREDICTION_NEWFTIC2021V0 %>% select(UWFID)
any(duplicated(FTIC2021_ID_GPA))
# UWFGPA_FTIC_202108 from data script the recent gpa
FTIC2021_UWFFALLGPA <- merge(FTIC2021_ID_GPA, UWFGPA_FTIC_202108 , by.x="UWFID", by.y="UNIV_ROW_ID", all.x = T) %>% 
    mutate(is.Stopout = ifelse(DEMO_TIME_FRAME != 202201, "Stopout", "Continuing" )) %>% select(-DEMO_TIME_FRAME)   
is.na(FTIC2021_UWFFALLGPA$UWFGPA_TEMP) <- sapply(FTIC2021_UWFFALLGPA$UWFGPA_TEMP, is.infinite) # replace inf to na
#UWFGPA_FTIC_202108 look data script
gpana <- FTIC2021_UWFFALLGPA[is.na(FTIC2021_UWFFALLGPA$UWFGPA_TEMP), ]
FTIC2021_UWFFALLGPA[FTIC2021_UWFFALLGPA$UWFGPA_TEMP == Inf,  ] # early ftic stopouts
mean(FTIC2021_UWFFALLGPA$UWFGPA_TEMP, na.rm = T)  #[1] 3.121091 returned spring FTIC

OUTPUT_PREDICTION_NEWFTIC2021V1 <- merge(OUTPUT_PREDICTION_NEWFTIC2021V0,FTIC2021_UWFFALLGPA , by="UWFID", all = T) %>% 
    relocate(c("PREDICTION_NEWFTIC","codeProb_APR"), .after = TIER2021) %>%
    mutate(codeProb_APR2 = cut(PREDICTION_NEWFTIC, breaks = c(0, 0.79, 0.89, 1), labels =c("high-risk","moderate-risk","low-risk") )) %>% 
    relocate(codeProb_APR2, .after = codeProb_APR) %>% 
    mutate(AVEUWFFALL1GPA =  ifelse(is.na(UWFGPA_TEMP), "WithdrawnFall",
        ifelse(UWFGPA_TEMP < 2.77, "Below2.77", "Above2.77"))) %>% 
    mutate(FALL1GPA = ifelse(is.na(UWFGPA_TEMP), "Withdrawn",
                             ifelse(UWFGPA_TEMP < 2.00, "Below2.00",
                                    ifelse(UWFGPA_TEMP < 2.77 ,"UWFGPAFALL1[2.00,2.77)", "Above2.77"))))

fallgpa_na <- OUTPUT_PREDICTION_NEWFTIC2021V1[is.na(OUTPUT_PREDICTION_NEWFTIC2021V1$AVEUWFFALL1GPA),]    
head(OUTPUT_PREDICTION_NEWFTIC2021V1[, 68:79],50)
mean(OUTPUT_PREDICTION_NEWFTIC2021V1$UWFGPA_TEMP, na.rm = T) #[1] 3.121091
addmargins(table(OUTPUT_PREDICTION_NEWFTIC2021V1$is.Stopout))
write.csv(OUTPUT_PREDICTION_NEWFTIC2021V1, "OUTPUT_PREDICTION_NEWFTIC2021V1.csv", row.names = F)
colnames(trim_apr_data2_V0)
transf_hrs <- trim_apr_data2_V0 %>% select(UWFID, TRANSFER_HOURS_EARNED)
library(readr)
OUTPUT_PREDICTION_NEWFTIC2021V1 <- read_csv("OUTPUT_PREDICTION_NEWFTIC2021V1.csv") 
OUTPUT_PREDICTION_NEWFTIC2021V2 <- merge(OUTPUT_PREDICTION_NEWFTIC2021V1,transf_hrs, by="UWFID", all.x = T ) %>% 
    select(-PROGRAM_DESC.y, -APPLICANT_TIER,-PROGRAM_DESC.x,-TIER_SCORE.x,-TIER_SCORE.y)
write.csv(OUTPUT_PREDICTION_NEWFTIC2021V2,"OUTPUT_PREDICTION_NEWFTIC2021V2.csv", row.names = F) # add transfer hours for inexperienced FTIC
```

### add better gpa from course taken

```{r}
library(readr)
OUTPUT_PREDICTION_NEWFTIC2021V2 <- read_csv("OUTPUT_PREDICTION_NEWFTIC2021V2.csv")
UWFGPA_FTIC_V0 <- read_csv("G:/Shared drives/HMCSE-PAM Lab/Jay's Space/_HIGH_PRIORITY_PROJECTS/APR/01 FILES/UWFGPA_FTIC_V0.csv") # 1st year gpa
# from APR folder
UWFGPA_FTIC_V0[UWFGPA_FTIC_V0$F1_UWFID=="970607265",]
OUTPUT_PREDICTION_NEWFTIC2021V3 <- merge(OUTPUT_PREDICTION_NEWFTIC2021V2, UWFGPA_FTIC_V0,  by.x="UWFID", by.y =  "F1_UWFID", all.x = T) %>%  # filtered for 2021 fall only
    select(1:86, contains("CRS")) %>% 
     mutate(codeProb_APR4 = cut(PREDICTION_NEWFTIC, breaks = c(0, 0.6900, 0.8600, 0.8900, 1), 
                               labels =c("high-risk","moderate-risk2","moderate-risk1", "low-risk") )) %>% 
    relocate(codeProb_APR4, .after =codeProb_APR3 ) %>% 
    mutate(FALL1STATUS = ifelse(is.na(CRS_crs_DEMO_TIME),"Withdrawn",
                                ifelse(F1_GPA2.00 == "Stopout", "Stopout",
                                ifelse(F1_DEMO_TIME_FRAME == 202201, "Continuing","Others")))) %>% 
    mutate(GPA_STATUS = ifelse(is.na(CRS_CUM_GPA), "Withdrawn",
                             ifelse(CRS_CUM_GPA < 2.00, "Below2.00",
                                    ifelse(CRS_CUM_GPA < 2.77 ,"UWFGPAFALL1[2.00,2.77)", "Above2.77")))) %>% 
     mutate(AVEGPA_STATUS =  ifelse(is.na(CRS_CUM_GPA), "Withdrawn",
        ifelse(CRS_CUM_GPA < 2.77, "Below2.77", "Above2.77"))) %>% 
     mutate(GPA2.00_STATUS =  ifelse(is.na(CRS_CUM_GPA), "Withdrawn",
        ifelse(CRS_CUM_GPA < 2.00, "Below2.00", "Above2.00")))
    
addmargins(table(OUTPUT_PREDICTION_NEWFTIC2021V3$AVEGPA_STATUS, OUTPUT_PREDICTION_NEWFTIC2021V3$GPA2.00_STATUS))  # 11 no prediction
NA_withdrawn <- OUTPUT_PREDICTION_NEWFTIC2021V3[is.na(OUTPUT_PREDICTION_NEWFTIC2021V3$FALL1STATUS),]
write.csv(OUTPUT_PREDICTION_NEWFTIC2021V3,"OUTPUT_PREDICTION_NEWFTIC2021V3.csv",row.names = F)
```


